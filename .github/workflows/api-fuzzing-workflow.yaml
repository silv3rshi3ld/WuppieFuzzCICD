# API Fuzzing Pipeline with Docker Swarm

name: API Fuzzing Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  contents: read

env:
  DOCKER_NETWORK_NAME: cicd_network
  VAMPI_RESTLER_PORT: 5012
  VAMPI_WUPPIEFUZZ_PORT: 5022
  VAMPI_EVOMASTER_PORT: 5032
  BASE_DIR: ${{ github.workspace }}
  FUZZERS: restler wuppiefuzz evomaster
  MAX_STARTUP_RETRIES: 3
  HEALTH_CHECK_TIMEOUT: 30
  NETWORK_TIMEOUT: 60

jobs:
  # 1. Initial cleanup
  cleanup:
    runs-on: self-hosted
    steps:
      - name: Cleanup Previous Setup
        run: |
          echo "Cleaning up previous setup..."
          # Kill any processes using known ports
          for port in ${{ env.VAMPI_RESTLER_PORT }} ${{ env.VAMPI_WUPPIEFUZZ_PORT }} ${{ env.VAMPI_EVOMASTER_PORT }}; do
            pid=$(lsof -ti :$port) || true
            if [ -n "$pid" ]; then
              echo "Killing process using port $port"
              kill -9 $pid || echo "Failed to kill process on port $port"
            fi
          done
          # Cleanup Docker containers
          if sudo docker ps -q | grep -q .; then
            sudo docker ps -q | xargs sudo docker stop || echo "Failed to stop some running containers"
          fi
          if sudo docker ps -aq | grep -q .; then
            sudo docker ps -aq | xargs sudo docker rm || echo "Failed to remove some containers"
          fi
          # Cleanup Docker network
          if sudo docker network ls | grep -q "${{ env.DOCKER_NETWORK_NAME }}"; then
            if ! sudo docker network rm "${{ env.DOCKER_NETWORK_NAME }}"; then
              echo "Failed to remove network ${{ env.DOCKER_NETWORK_NAME }}, it might be in use"
            fi
          fi
          echo "Cleanup completed."
          sleep 5

  # 2. Initialize Swarm infrastructure
  initialize_swarm:
    needs: cleanup
    runs-on: self-hosted
    outputs:
      swarm-manager-ip: ${{ steps.setup_swarm.outputs.swarm-manager-ip }}
      swarm-worker-token: ${{ steps.setup_swarm.outputs.swarm-worker-token }}
      network-id: ${{ steps.setup_network.outputs.network-id }}
      manager-hostname: ${{ steps.setup_swarm.outputs.manager-hostname }}
      swarm-initialized: ${{ steps.setup_swarm.outputs.swarm-initialized }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Count Active Runners
        id: count_runners
        run: |
          echo "TOTAL_RUNNERS=$(gh api /repos/${{ github.repository }}/actions/runners | jq '.total_count')" >> $GITHUB_ENV
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Make manage-swarm.sh executable
        run: chmod +x ./scripts/manage-swarm.sh

      - name: Manage Swarm State
        id: setup_swarm
        env:
          MANAGER_IP: ${{ secrets.MANAGER_IP }}
        run: |
          ./scripts/manage-swarm.sh ${{ env.TOTAL_RUNNERS }}
          
          # Set outputs for other jobs
          echo "swarm-manager-ip=$MANAGER_IP" >> $GITHUB_OUTPUT
          WORKER_TOKEN=$(sudo docker swarm join-token worker -q)
          echo "swarm-worker-token=$WORKER_TOKEN" >> $GITHUB_OUTPUT
          echo "manager-hostname=$(hostname)" >> $GITHUB_OUTPUT
          echo "swarm-initialized=true" >> $GITHUB_OUTPUT

      - name: Setup Docker Network
        id: setup_network
        run: |
          # Check if network exists first
          if ! sudo docker network ls | grep -q "${{ env.DOCKER_NETWORK_NAME }}"; then
            echo "Creating overlay network ${{ env.DOCKER_NETWORK_NAME }}"
            NETWORK_ID=$(sudo docker network create --driver overlay --attachable ${{ env.DOCKER_NETWORK_NAME }})
            echo "network-id=$NETWORK_ID" >> $GITHUB_OUTPUT
          else
            echo "Network ${{ env.DOCKER_NETWORK_NAME }} already exists"
            NETWORK_ID=$(sudo docker network ls --filter name=${{ env.DOCKER_NETWORK_NAME }} --format "{{.ID}}")
            echo "network-id=$NETWORK_ID" >> $GITHUB_OUTPUT
          fi
          
          # Verify network was created/exists and is overlay type
          if ! sudo docker network inspect ${{ env.DOCKER_NETWORK_NAME }} --format "{{.Driver}}" | grep -q "overlay"; then
            echo "::error::Network ${{ env.DOCKER_NETWORK_NAME }} is not an overlay network"
            exit 1
          fi

  # 3. Configure Swarm Workers
  configure_workers:
    needs: initialize_swarm
    runs-on: self-hosted
    steps:
      - name: Debug Runner Info
        run: |
          echo "Runner Name: ${{ runner.name }}"
          echo "Hostname: $(hostname)"
          echo "Manager Hostname: ${{ needs.initialize_swarm.outputs.manager-hostname }}"

      - name: Join Swarm (Worker Node)
        if: needs.initialize_swarm.outputs.swarm-initialized == 'true' && runner.name != needs.initialize_swarm.outputs.manager-hostname
        env:
          MANAGER_IP: ${{ secrets.MANAGER_IP }}
        run: |
          # Check if already in swarm
          if sudo docker info 2>/dev/null | grep -q "Swarm: active"; then
            echo "Node is already part of a swarm"
            exit 0
          fi

          # Configure Docker daemon
          sudo systemctl stop docker || true
          sudo sed -i 's/^ExecStart=.*/ExecStart=\/usr\/bin\/dockerd -H fd:\/\/ --containerd=\/run\/containerd\/containerd.sock --iptables=true --ip-masq=true --ip-forward=true/' /lib/systemd/system/docker.service
          sudo systemctl daemon-reload
          sudo systemctl start docker
          
          # Wait for Docker to be ready
          timeout 30s bash -c 'until sudo docker info &>/dev/null; do sleep 1; done'
          
          # Verify manager IP
          echo "Attempting to join swarm at $MANAGER_IP:2377"
          if ! ping -c 1 $MANAGER_IP > /dev/null 2>&1; then
            echo "::error::Cannot ping manager at $MANAGER_IP"
            exit 1
          fi
          
          # Join swarm
          if ! timeout 30s sudo docker swarm join --token ${{ needs.initialize_swarm.outputs.swarm-worker-token }} $MANAGER_IP:2377; then
            echo "::error::Failed to join swarm"
            exit 1
          fi

      - name: Label Workers (Manager Only)
        if: needs.initialize_swarm.outputs.swarm-initialized == 'true' && runner.name == needs.initialize_swarm.outputs.manager-hostname
        run: |
          # Get all worker nodes
          WORKER_NODES=($(sudo docker node ls --format '{{.Hostname}}' --filter role=worker))
          FUZZERS=(restler wuppiefuzz evomaster)
          
          # Label each worker with a different fuzzer
          for i in "${!WORKER_NODES[@]}"; do
            if [ $i -lt ${#FUZZERS[@]} ]; then
              WORKER="${WORKER_NODES[$i]}"
              FUZZER="${FUZZERS[$i]}"
              echo "Labeling worker node $WORKER for fuzzer $FUZZER"
              sudo docker node update --label-add type=fuzzer --label-add fuzzer=$FUZZER "$WORKER"
            fi
          done

  # 4. Verify Swarm setup
  verify_swarm:
    needs: [initialize_swarm, configure_workers]
    runs-on: self-hosted
    if: success()
    steps:
      - name: Verify Swarm and Network
        run: |
          # Verify swarm mode is active
          if ! sudo docker info | grep -q "Swarm: active"; then
            echo "::error::Not in swarm mode - swarm initialization may have failed"
            exit 1
          fi
          
          # Verify network exists and is overlay type
          if ! sudo docker network ls --filter driver=overlay | grep -q "${{ env.DOCKER_NETWORK_NAME }}"; then
            echo "::error::Required overlay network ${{ env.DOCKER_NETWORK_NAME }} not found"
            sudo docker network ls
            exit 1
          fi
          
          # List nodes and their roles
          echo "Swarm Nodes:"
          sudo docker node ls
          
          echo "Swarm configuration verified successfully"

  # 5. Prepare OpenAPI specs
  prepare_specs:
    needs: verify_swarm
    runs-on: self-hosted
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4.0.0

      - name: Copy OpenAPI Specs to Volumes
        run: |
          # Create temporary directory
          mkdir -p specs_temp
          cp services/vampi/openapi_specs/openapi3.yml specs_temp/
          
          # Copy specs to volumes
          sudo docker run --rm \
            -v $(pwd)/specs_temp:/source \
            -v openapi_spec:/dest \
            alpine cp /source/openapi3.yml /dest/

  # 6. Build and push images
  build_and_push_images:
    needs: verify_swarm
    runs-on: self-hosted
    strategy:
      matrix:
        service: [vampi-vulnerable, wuppiefuzz, restler, evomaster]
      fail-fast: false
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4.0.0

      - name: Start Local Registry
        run: |
          # Stop any existing registry with elevated privileges
          sudo docker stop registry || true
          sudo docker rm registry || true
          
          # Start new registry with elevated privileges
          sudo docker run -d \
            --name registry \
            --restart=always \
            -p 5000:5000 \
            registry:2
          
          # Wait for registry to be ready
          for i in $(seq 1 30); do
            if curl -s http://localhost:5000/v2/ > /dev/null; then
              echo "Registry is ready"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "Registry failed to start"
              exit 1
            fi
            echo "Waiting for registry... ($i/30)"
            sleep 1
          done

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            network=host

      - name: Build and Push Image
        run: |
          # Set registry address
          REGISTRY=localhost:5000
          
          # Determine service directory and Dockerfile
          SERVICE_DIR=services/${{ matrix.service == 'vampi-vulnerable' && 'vampi' || matrix.service }}
          DOCKERFILE=${{ matrix.service != 'vampi-vulnerable' && format('Dockerfile.{0}', matrix.service) || 'Dockerfile' }}
          
          # For WuppieFuzz, ensure source code is available
          if [ "${{ matrix.service }}" = "wuppiefuzz" ]; then
            echo "Preparing WuppieFuzz build context..."
            git clone https://github.com/TNO-S3/WuppieFuzz.git temp_wuppiefuzz
            cp -r temp_wuppiefuzz/* $SERVICE_DIR/
            rm -rf temp_wuppiefuzz
          fi
          
          # Build and push
          cd $SERVICE_DIR
          
          # Special handling for VAmPI instances
          if [ "${{ matrix.service }}" = "vampi-vulnerable" ]; then
            # Build VAmPI instances for each fuzzer
            for FUZZER in restler wuppiefuzz evomaster; do
              echo "Building VAmPI for $FUZZER"
              sudo docker buildx build \
                --platform linux/amd64 \
                --file $DOCKERFILE \
                --build-arg vulnerable=1 \
                --tag $REGISTRY/vampi-vulnerable-$FUZZER:${TAG:-latest} \
                --network host \
                --push \
                .
            done
          else
            # Build other services normally
            sudo docker buildx build \
              --platform linux/amd64 \
              --file $DOCKERFILE \
              --tag $REGISTRY/${{ matrix.service }}:${TAG:-latest} \
              --network host \
              --push \
              .
          fi

  # 7. Deploy stack
  deploy_stack:
    needs: [prepare_specs, build_and_push_images]
    runs-on: self-hosted
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4.0.0

      - name: Deploy Stack
        run: |
          export REGISTRY=localhost:5000
          export TAG=${TAG:-latest}
          
          # Create docker-compose override for VAmPI instances
          cat > docker-compose.vampi.override.yml <<EOF
          version: '3.8'
          services:
            vampi-restler:
              image: $REGISTRY/vampi-vulnerable-restler:$TAG
              environment:
                - vulnerable=1
              ports:
                - "${{ env.VAMPI_RESTLER_PORT }}:5000"
              networks:
                - ${{ env.DOCKER_NETWORK_NAME }}
              deploy:
                placement:
                  constraints:
                    - node.labels.fuzzer == restler
            
            vampi-wuppiefuzz:
              image: $REGISTRY/vampi-vulnerable-wuppiefuzz:$TAG
              environment:
                - vulnerable=1
              ports:
                - "${{ env.VAMPI_WUPPIEFUZZ_PORT }}:5000"
              networks:
                - ${{ env.DOCKER_NETWORK_NAME }}
              deploy:
                placement:
                  constraints:
                    - node.labels.fuzzer == wuppiefuzz
            
            vampi-evomaster:
              image: $REGISTRY/vampi-vulnerable-evomaster:$TAG
              environment:
                - vulnerable=1
              ports:
                - "${{ env.VAMPI_EVOMASTER_PORT }}:5000"
              networks:
                - ${{ env.DOCKER_NETWORK_NAME }}
              deploy:
                placement:
                  constraints:
                    - node.labels.fuzzer == evomaster
          EOF
          
          # Remove any existing stack
          sudo docker stack rm fuzzing-stack || true
          sleep 10
          
          # Deploy the new stack
          RETRY_COUNT=0
          MAX_RETRIES=3
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Deploying stack (Attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"
            
            if sudo docker stack deploy -c docker-compose.vampi.override.yml fuzzing-stack; then
              # Wait for services to be running
              echo "Waiting for services to start..."
              for i in $(seq 1 60); do
                RUNNING_COUNT=$(sudo docker stack services fuzzing-stack --format "{{.Replicas}}" | grep -c "1/1" || echo "0")
                EXPECTED_COUNT=3  # One VAmPI instance per fuzzer
                if [ "$RUNNING_COUNT" -eq "$EXPECTED_COUNT" ]; then
                  echo "All services are running"
                  sudo docker stack services fuzzing-stack
                  exit 0
                fi
                echo "Services running: $RUNNING_COUNT/$EXPECTED_COUNT"
                sleep 2
              done
            fi
            
            echo "Attempt $((RETRY_COUNT + 1)) failed, cleaning up..."
            sudo docker stack rm fuzzing-stack || true
            sleep 10
            RETRY_COUNT=$((RETRY_COUNT + 1))
          done
          
          echo "::error::Failed to deploy stack after $MAX_RETRIES attempts"
          sudo docker stack services fuzzing-stack || true
          exit 1

  # 8. Run fuzzing
  run_fuzzing:
    needs: deploy_stack
    runs-on: self-hosted
    strategy:
      matrix:
        fuzzer: [restler, wuppiefuzz, evomaster]
      fail-fast: false
    steps:
      - name: Run Fuzzing Tests
        run: |
          # Determine VAmPI port based on fuzzer
          case "${{ matrix.fuzzer }}" in
            "restler")
              VAMPI_PORT=${{ env.VAMPI_RESTLER_PORT }}
              ;;
            "wuppiefuzz")
              VAMPI_PORT=${{ env.VAMPI_WUPPIEFUZZ_PORT }}
              ;;
            "evomaster")
              VAMPI_PORT=${{ env.VAMPI_EVOMASTER_PORT }}
              ;;
          esac
          
          # Wait for VAmPI to be ready
          echo "Waiting for VAmPI (${{ matrix.fuzzer }}) to be ready..."
          for i in $(seq 1 30); do
            if curl -s http://localhost:$VAMPI_PORT/health > /dev/null; then
              echo "VAmPI is ready"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "::error::VAmPI failed to become ready"
              exit 1
            fi
            echo "Waiting for VAmPI... ($i/30)"
            sleep 2
          done

          # Monitor fuzzing services
          echo "Monitoring fuzzing services..."
          TIMEOUT=3600  # 1 hour timeout
          START_TIME=$(date +%s)
          
          while true; do
            CURRENT_TIME=$(date +%s)
            ELAPSED_TIME=$((CURRENT_TIME - START_TIME))
            
            if [ $ELAPSED_TIME -gt $TIMEOUT ]; then
              echo "Fuzzing timeout reached"
              break
            fi
            
            # Check service status
            if ! sudo docker stack services fuzzing-stack --format "{{.Name}} {{.Replicas}}"; then
              echo "::error::Failed to get service status"
              exit 1
            fi
            
            # Check for completed fuzzing
            COMPLETED_COUNT=$(sudo docker service logs fuzzing-stack_${{ matrix.fuzzer }} 2>&1 | grep -c "Fuzzing completed" || true)
            
            if [ $COMPLETED_COUNT -gt 0 ]; then
              echo "Fuzzing completed successfully"
              break
            fi
            
            echo "Fuzzing in progress... (${ELAPSED_TIME}s elapsed)"
            sleep 30
          done

      - name: Collect Results
        run: |
          mkdir -p fuzzing_results/${{ matrix.fuzzer }}
          
          # Copy results from volumes
          sudo docker run --rm \
            -v ${{ matrix.fuzzer }}_output:/results \
            -v $(pwd)/fuzzing_results/${{ matrix.fuzzer }}:/output \
            alpine cp -r /results/* /output/

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: fuzzing-results-${{ matrix.fuzzer }}
          path: fuzzing_results/${{ matrix.fuzzer }}
          retention-days: 7

  # 9. Summarize results
  summarize_results:
    needs: run_fuzzing
    runs-on: self-hosted
    if: always()
    steps:
      - name: Download Results
        uses: actions/download-artifact@v4
        with:
          pattern: fuzzing-results-*
          path: all_results
          merge-multiple: true

      - name: List Results
        run: |
          echo "Listing Results:"
          ls -la all_results || echo "No results found."

      - name: Final Cleanup
        run: |
          echo "Cleaning up resources..."
          sudo docker stack rm fuzzing-stack || true
          sudo docker container prune -f
          sudo docker network prune -f
